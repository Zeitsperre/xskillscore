{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "See the [API](https://xskillscore.readthedocs.io/en/stable/api.html) for more detailed information, examples, formulas, and references for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import xskillscore as xs\n",
    "\n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate some sample gridded data. Our data has three time steps, and a 4x5 latitude/longitude grid. `obs` denotes some verification data (sometimes termed `y`) and `fct` some forecast data (e.g. from a statistical or dynamical model; sometimes termed `yhat`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.DataArray(\n",
    "    np.random.rand(3, 4, 5),\n",
    "    coords=[\n",
    "        xr.cftime_range(\"2000-01-01\", \"2000-01-03\", freq=\"D\"),\n",
    "        np.arange(4),\n",
    "        np.arange(5),\n",
    "    ],\n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"var\",\n",
    ")\n",
    "fct = obs.copy()\n",
    "fct.values = np.random.rand(3, 4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Metrics\n",
    "\n",
    "`xskillscore` offers a suite of correlation-based and distance-based deterministic metrics:\n",
    "\n",
    "### Correlation-Based \n",
    "\n",
    "* Effective Sample Size (`effective_sample_size`)\n",
    "* Pearson Correlation (`pearson_r`)\n",
    "* Pearson Correlation effective p value (`pearson_r_eff_p_value`)\n",
    "* Pearson Correlation p value (`pearson_r_p_value`)\n",
    "* Slope of Linear Fit (`linslope`)\n",
    "* Spearman Correlation (`spearman_r`)\n",
    "* Spearman Correlation effective p value (`spearman_r_eff_p_value`)\n",
    "* Spearman Correlation p value (`spearman_r_p_value`)\n",
    "\n",
    "### Distance-Based\n",
    "\n",
    "* Coefficient of Determination (`r2`)\n",
    "* Mean Absolute Error (`mae`)\n",
    "* Mean Absolute Percentage Error (`mape`)\n",
    "* Mean Error (`me`)\n",
    "* Mean Squared Error (`mse`)\n",
    "* Median Absolute Error (`median_absolute_error`)\n",
    "* Root Mean Squared Error (`rmse`)\n",
    "* Symmetric Mean Absolute Percentage Error (`smape`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the functions is very straight-forward. All deterministic functions take the form `func(a, b, dim=None, **kwargs)`. **Notice that the original dataset is reduced by the dimension passed.** I.e., since we passed `time` as the dimension here, we are returned an object with dimensions `(lat, lon)`. For correlation metrics `dim` cannot be `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = xs.pearson_r(obs, fct, dim=\"time\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = xs.pearson_r_p_value(obs, fct, dim=\"time\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify multiple axes for deterministic metrics. Here, we apply it over the latitude and longitude dimension (a pattern correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = xs.pearson_r(obs, fct, dim=[\"lat\", \"lon\"])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All deterministic metrics except for `effective_sample_size`, `pearson_r_eff_p_value` and `spearman_r_eff_p_value` can take the kwarg `weights=...`. `weights` should be a DataArray of the size of the reduced dimension (e.g., if time is being reduced it should be of length 3 in our example).\n",
    "\n",
    "Weighting is a common practice when working with observations and model simulations of the Earth system. When working with rectilinear grids, one can weight the data by the cosine of the latitude, which is maximum at the equator and minimum at the poles (as in the below example). More complicated model grids tend to be accompanied by a cell area varaible, which could also be passed into this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs2 = xr.DataArray(\n",
    "    np.random.rand(3, 180, 360),\n",
    "    coords=[\n",
    "        xr.cftime_range(\"2000-01-01\", \"2000-01-03\", freq=\"D\"),\n",
    "        np.linspace(-89.5, 89.5, 180),\n",
    "        np.linspace(-179.5, 179.5, 360),\n",
    "    ],\n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    ")\n",
    "fct2 = obs2.copy()\n",
    "fct2.values = np.random.rand(3, 180, 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make weights as cosine of the latitude and broadcast\n",
    "weights = np.cos(np.deg2rad(obs2.lat))\n",
    "_, weights = xr.broadcast(obs2, weights)\n",
    "\n",
    "# Remove the time dimension from weights\n",
    "weights = weights.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_weighted = xs.pearson_r(obs2, fct2, dim=[\"lat\", \"lon\"], weights=weights)\n",
    "print(r_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_unweighted = xs.pearson_r(obs2, fct2, dim=[\"lat\", \"lon\"], weights=None)\n",
    "print(r_unweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass the optional boolean kwarg `skipna`. If `True`, ignore any NaNs (pairwise) in `obs` and `fct` when computing the result. If `False`, return NaNs anywhere there are pairwise NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_with_nans = obs.where(obs.lat > 1)\n",
    "fct_with_nans = fct.where(fct.lat > 1)\n",
    "print(obs_with_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_with_skipna = xs.mae(obs_with_nans, fct_with_nans, dim=[\"lat\", \"lon\"], skipna=True)\n",
    "print(mae_with_skipna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_without_skipna = xs.mae(\n",
    "    obs_with_nans, fct_with_nans, dim=[\"lat\", \"lon\"], skipna=False\n",
    ")\n",
    "print(mae_without_skipna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Metrics\n",
    "\n",
    "`xskillscore` offers a suite of probabilistic metrics:\n",
    "\n",
    "* Brier Score (`brier_score`)\n",
    "* Brier scores of an ensemble for exceeding given thresholds (`threshold_brier_score`)\n",
    "* Continuous Ranked Probability Score with a gaussian distribution (`crps_gaussian`)\n",
    "* Continuous Ranked Probability Score with numerical integration of the normal distribution (`crps_quadrature`)\n",
    "* Continuous Ranked Probability Score with the ensemble distribution (`crps_ensemble`)\n",
    "* Discrimination (`discrimination`)\n",
    "* Rank Histogram (`rank_histogram`)\n",
    "* Ranked Probability Score (`rps`)\n",
    "* Receiver Operating Characteristic (`roc`)\n",
    "* Reliability (`reliability`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create some data with an ensemble member dimension. In this case, we envision an ensemble forecast with multiple members to validate against our theoretical observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs3 = xr.DataArray(\n",
    "    np.random.rand(4, 5),\n",
    "    coords=[np.arange(4), np.arange(5)],\n",
    "    dims=[\"lat\", \"lon\"],\n",
    "    name=\"var\",\n",
    ")\n",
    "fct3 = xr.DataArray(\n",
    "    np.random.rand(3, 4, 5),\n",
    "    coords=[np.arange(3), np.arange(4), np.arange(5)],\n",
    "    dims=[\"member\", \"lat\", \"lon\"],\n",
    "    name=\"var\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Ranked Probability Score with the ensemble distribution. Pass `dim=[]` to get the same behaviour as `properscoring.crps_ensemble` without any averaging over `dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_ensemble = xs.crps_ensemble(obs3, fct3, dim=[])\n",
    "print(crps_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CRPS with a Gaussian distribution requires two parameters: $\\mu$ and $\\sigma$ from the forecast distribution. Here, we just use the ensemble mean and ensemble spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_gaussian = xs.crps_gaussian(obs3, fct3.mean(\"member\"), fct3.std(\"member\"), dim=[])\n",
    "print(crps_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CRPS quadrature metric requires a callable distribution function. Here we use `norm` from `scipy.stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "crps_quadrature = xs.crps_quadrature(obs3, norm, dim=[])\n",
    "print(crps_quadrature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a threshold Brier Score, to score hits over a certain threshold. Ranked Probability Score for two categories yields the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_brier_score = xs.threshold_brier_score(obs3, fct3, 0.5, dim=None)\n",
    "print(threshold_brier_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_score = xs.brier_score(obs3 > 0.5, (fct3 > 0.5).mean(\"member\"))\n",
    "print(brier_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps = xs.rps(obs3 > 0.5, fct3 > 0.5, category_edges=np.array([0.5]))\n",
    "print(rps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_histogram = xs.rank_histogram(obs3, fct3)\n",
    "print(rank_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = xs.discrimination(obs3 > 0.5, (fct3 > 0.5).mean(\"member\"))\n",
    "print(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = xs.reliability(obs3 > 0.5, (fct3 > 0.5).mean(\"member\"))\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for probabilistic forecasts and bin_edges='continuous' default\n",
    "roc = xs.roc(\n",
    "    obs3 > 0.5, (fct3 > 0.5).mean(\"member\"), return_results=\"all_as_metric_dim\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot([0, 1], [0, 1], \"k:\")\n",
    "roc.to_dataset(dim=\"metric\").plot.scatter(\n",
    "    y=\"true positive rate\", x=\"false positive rate\"\n",
    ")\n",
    "roc.sel(metric=\"area under curve\").values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency-Based\n",
    "\n",
    "To work with contingency-based scoring, first instantiate a `Contingency` object by passing in your observations, forecast, and observation/forecast bin edges. See https://www.cawcr.gov.au/projects/verification/#Contingency_table for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dichotomous_category_edges = np.array([0, 0.5, 1])  # \"dichotomous\" mean two-category\n",
    "dichotomous_contingency = xs.Contingency(\n",
    "    obs, fct, dichotomous_category_edges, dichotomous_category_edges, dim=[\"lat\", \"lon\"]\n",
    ")\n",
    "dichotomous_contingency_table = dichotomous_contingency.table\n",
    "print(dichotomous_contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    dichotomous_contingency_table.to_dataframe()\n",
    "    .pivot_table(\n",
    "        index=[\"forecasts_category\", \"forecasts_category_bounds\"],\n",
    "        columns=[\"observations_category\", \"observations_category_bounds\"],\n",
    "    )\n",
    "    .round(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores based on the constructed contingency table can be called via class methods. The available methods are:\n",
    "\n",
    "* Accuracy (`accuracy`)\n",
    "* Bias Score (`bias_score`)\n",
    "* Equitable Threat Score (`equit_threat_score`)\n",
    "* False Alarms / False Positives (`false_alarms`)\n",
    "* False Alarm Ratio / False Discovery Rate (`false_alarm_ratio`)\n",
    "* False Alarm Rate / False Positive Rate / Fall-out (`false_alarm_rate`)\n",
    "* Gerrity Score (`gerrity_score`)\n",
    "* Heidke Score / Cohen's Kappa (`heidke_score`)\n",
    "* Hit Rate / Recall / Sensitivity / True Positive Rate (`hit_rate`)\n",
    "* Hits / True Positives (`hits`)\n",
    "* Misses / False Negatives (`misses`)\n",
    "* Odds Ratio (`odds_ratio`)\n",
    "* Odds Ratio Skill Score (`odds_ratio_skill_score`)\n",
    "* Peirce Score (`peirce_score`)\n",
    "* Receiver Operating Characteristic (`roc`)\n",
    "* Success Ratio / Precision / Positive Predictive Value (`success_ratio`)\n",
    "* Threat Score / Critical Success Index (`threat_score`)\n",
    "\n",
    "Below, we share a few examples of these in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dichotomous_contingency.bias_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dichotomous_contingency.hit_rate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dichotomous_contingency.false_alarm_rate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dichotomous_contingency.odds_ratio_skill_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can leverage multi-category edges to make use of some scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_category_edges = np.array([0, 0.25, 0.75, 1])\n",
    "multicategory_contingency = xs.Contingency(\n",
    "    obs, fct, multi_category_edges, multi_category_edges, dim=[\"lat\", \"lon\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multicategory_contingency.accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multicategory_contingency.heidke_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multicategory_contingency.peirce_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multicategory_contingency.gerrity_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for deterministic forecasts and bin_edges\n",
    "roc = xs.roc(obs, fct, np.linspace(0, 1, 11), return_results=\"all_as_metric_dim\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot([0, 1], [0, 1], \"k:\")\n",
    "roc.to_dataset(dim=\"metric\").plot.scatter(\n",
    "    y=\"true positive rate\", x=\"false positive rate\"\n",
    ")\n",
    "roc.sel(metric=\"area under curve\").values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative\n",
    "\n",
    "Tests to compare whether one forecast is significantly better than another one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "obs_1d = xr.DataArray(\n",
    "    np.random.rand(length),\n",
    "    coords=[\n",
    "        np.arange(length),\n",
    "    ],\n",
    "    dims=[\"time\"],\n",
    "    name=\"var\",\n",
    ")\n",
    "fct_1d = obs_1d.copy()\n",
    "fct_1d.values = np.random.rand(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given you want to test whether one forecast is better than another forecast\n",
    "significantly_different, walk, confidence = xs.sign_test(\n",
    "    fct_1d, fct_1d + 0.2, obs_1d, time_dim=\"time\", metric=\"mae\", orientation=\"negative\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk.plot()\n",
    "confidence.plot(c=\"gray\")\n",
    "(-1 * confidence).plot(c=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Half-width Confidence Interval test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a worse forecast with high but different to perfect correlation and choose RMSE as the distance metric\n",
    "fct_1d_worse = fct_1d.copy()\n",
    "step = 3\n",
    "fct_1d_worse[::step] = fct_1d[::step].values + 0.1\n",
    "metric = \"rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half-with of the confidence interval at level alpha is larger than the RMSE differences,\n",
    "# therefore not significant\n",
    "alpha = 0.05\n",
    "significantly_different, diff, hwci = xs.halfwidth_ci_test(\n",
    "    fct_1d, fct_1d_worse, obs_1d, metric, time_dim=\"time\", dim=[], alpha=alpha\n",
    ")\n",
    "print(diff)\n",
    "print(hwci)\n",
    "print(\n",
    "    f\"RMSEs significantly different at level {alpha} : {bool(significantly_different)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple tests\n",
    "\n",
    "A statistical test is applied multiple times on a spatial grid. `multipletests` helps controlling the false discovery rate (FDR) of p values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = xs.pearson_r_p_value(fct, obs, \"time\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_corrected = xs.multipletests(\n",
    "    p, alpha=0.5, method=\"fdr_bh\", return_results=\"pvals_corrected\"\n",
    ")\n",
    "print(p_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not p_corrected.equals(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessors\n",
    "\n",
    "You can also use `xskillscore` as a method of your `xarray` Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset()\n",
    "ds[\"obs_var\"] = obs\n",
    "ds[\"fct_var\"] = fct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case that your Dataset contains both your observation and forecast variable, just pass them as strings into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.xs.pearson_r(\"obs_var\", \"fct_var\", dim=\"time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in a separate Dataset that contains your observations or forecast variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.drop_vars(\"fct_var\")\n",
    "print(ds.xs.pearson_r(\"obs_var\", fct, dim=\"time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "-   randomly resample the `time` dimension and then take mean over `time` to get resample threshold\n",
    "-   resample over `member` dimension to get uncertainty due to member sampling in hindcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create large one-dimensional array\n",
    "s = 1000\n",
    "f = xr.DataArray(\n",
    "    np.random.normal(size=s), dims=\"member\", coords={\"member\": np.arange(s)}, name=\"var\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample with replacement in that one dimension\n",
    "iterations = 100\n",
    "%timeit f_r = xs.resampling.resample_iterations(f, iterations, 'member', replace=True)\n",
    "# resample_iterations_idx is much (50x) faster because it involves no loops\n",
    "%timeit f_r = xs.resampling.resample_iterations_idx(f, iterations, 'member', replace=True)\n",
    "# but both do the same resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use `resample_iterations` for very large data, because very robust, chunksize stays contants and only more tasks are added\n",
    "- use `resample_iterations_idx` for small data always and very large data only, when chunked to small chunks in the other dimensions, because the function increases the input chunksize by factor `iterations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_r = xs.resampling.resample_iterations_idx(f, iterations, \"member\", replace=True)\n",
    "f.plot.hist(label=\"distribution\")\n",
    "f_r.mean(\"iteration\").plot.hist(label=\"resampled mean distribution\")\n",
    "plt.axvline(x=f.mean(\"member\"), c=\"k\", label=\"distribution mean\")\n",
    "plt.title(\"Gaussian distribution mean\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can calculate the distribution of the RMSE of 0 and f resampled over member\n",
    "xs.rmse(f_r, xr.zeros_like(f_r), dim=\"iteration\").plot.hist(\n",
    "    label=\"resampled RMSE distribution\"\n",
    ")\n",
    "# the gaussian distribution should have an RMSE with 0 of one\n",
    "plt.axvline(x=xs.rmse(f, xr.zeros_like(f)), c=\"k\", label=\"RMSE\")\n",
    "plt.title(\"RMSE between gaussian distribution and 0\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
