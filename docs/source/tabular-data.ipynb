{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Data\n",
    "\n",
    "`xskillscore` can be used on tabular data such as that stored in a `pandas.DataFrame`.\n",
    "\n",
    "It can be used most effectively when evaluating predictions over different fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xskillscore as xs\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California house prices dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small example is to take a dataset and evaluate the model according to a field (column).\n",
    "\n",
    "Load the California house prices dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "df[\"AveRooms\"] = df[\"AveRooms\"].round()\n",
    "df = df.rename(columns={\"MedHouseVal\": \"y\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dummy prediction column by adding noise to `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1, 1, size=len(df[\"y\"]))\n",
    "df[\"yhat\"] = (df[\"y\"] + (df[\"y\"] * noise)).clip(lower=df[\"y\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model over the field `AveRooms` using `pandas.groupby.apply` with `mean_squared_error` from `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby(\"AveRooms\").apply(lambda x: mean_squared_error(x[\"y\"], x[\"yhat\"])).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also do the following using `xskillscore`.\n",
    "\n",
    "First, structure the `pandas.DataFrame` to keep the core fields when converting to an `xarray` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = df.reset_index().set_index([\"index\", \"AveRooms\"])[[\"y\", \"yhat\"]]\n",
    "min_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to an `xarray.Dataset` using `pandas.DataFrame.to_xarray`. Note: This will create an array of `index` by `AveRooms` and pad the values that do not exist with `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = min_df.to_xarray()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You call now apply any metric from `xskillscore` using the accessor method. The input for the `dim` argument is `index` as we want to reduce this dimension and apply the metric over `AveRooms`. In addition, there are `nan`'s in the `xarray.Dataset` so you should use `skipna=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ds.xs.mse(\"y\", \"yhat\", dim=\"index\", skipna=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense to return the data in tabular form hence you can call `xarray.DataArray.to_series` to convert it to a `pandas.Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_series().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating predictions over many columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xskillscore` is built upon `xarray.apply_ufunc` which offers speed-up by vectorizing operations. As a result `xskillscore` can be faster than `pandas.groupby.apply`. This is espicially true if there are many samples in the dataset and if the predictions have to be evaluated over many fields.\n",
    "\n",
    "For this exercise we will create fake data for which the predictions have to be evaluated over three fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = np.arange(100)\n",
    "skus = np.arange(100)\n",
    "dates = pd.date_range(\"1/1/2020\", \"1/10/2020\", freq=\"D\")\n",
    "\n",
    "rows = []\n",
    "for _, date in enumerate(dates):\n",
    "    for _, store in enumerate(stores):\n",
    "        for _, sku in enumerate(skus):\n",
    "            rows.append(\n",
    "                dict(\n",
    "                    {\n",
    "                        \"DATE\": date,\n",
    "                        \"STORE\": store,\n",
    "                        \"SKU\": sku,\n",
    "                        \"y\": np.random.randint(9) + 1,\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "noise = np.random.uniform(-1, 1, size=len(df[\"y\"]))\n",
    "df[\"yhat\"] = (df[\"y\"] + (df[\"y\"] * noise)).clip(lower=df[\"y\"].min())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the `pandas.groupby.apply` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.groupby([\"STORE\", \"SKU\"]).apply(lambda x: mean_squared_error(x[\"y\"], x[\"yhat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time it using `xskillscore`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.set_index([\"DATE\", \"STORE\", \"SKU\"]).to_xarray().xs.mse(\n",
    "    \"y\", \"yhat\", dim=\"DATE\"\n",
    ").to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [xskillscore-tutorial](https://github.com/raybellwaves/xskillscore-tutorial) for further reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5607b67897ceeb4cb8d1a6f5e8f77cf995244d75ab9ff3b133e23bb37c07f75"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
